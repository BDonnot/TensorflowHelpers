{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save a random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_created = make_classification(n_samples=100, n_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"testds\"):\n",
    "    os.mkdir(\"testds\")\n",
    "pd.DataFrame(dataset_created[0]).to_csv(\"testds/X.csv\", index=False)\n",
    "pd.DataFrame(dataset_created[1]).to_csv(\"testds/Y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start to play with tensorflow: build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "filename_queueX = tf.train.string_input_producer([\"testds/X.csv\"])\n",
    "filename_queueY = tf.train.string_input_producer([\"testds/Y.csv\"])\n",
    "\n",
    "readerX = tf.TextLineReader( skip_header_lines=1)\n",
    "key, valueX = readerX.read(filename_queueX)\n",
    "\n",
    "readerY = tf.TextLineReader( skip_header_lines=1)\n",
    "key, valueY = readerY.read(filename_queueY)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the\n",
    "# decoded result.\n",
    "record_defaults = [[1.], [1.], [1.], [1.], [1.]]\n",
    "col1, col2, col3, col4, col5 = tf.decode_csv(valueX, record_defaults=record_defaults)\n",
    "features = tf.stack([col1, col2, col3, col4, col5])\n",
    "target = tf.decode_csv(valueY, record_defaults=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a session and have a look at what it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "for i in range(1200):\n",
    "    # Retrieve a single instance:\n",
    "    example, label = sess.run([features, target])\n",
    "    print(\"example : {}\".format(example))\n",
    "    print(\"label : {} | {}\".format(label, dataset[1][i] ))\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Datasets ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_rowX(csv_row):\n",
    "    record_defaults = [[0.0] for _ in range(5)]\n",
    "    row = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "    return row\n",
    "def read_rowY(csv_row):\n",
    "    record_defaults = [[0]]\n",
    "    row = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataX = tf.contrib.data.TextLineDataset([\"testds/X.csv\"]).skip(1).map(lambda line: read_rowX(line))\n",
    "dataY = tf.contrib.data.TextLineDataset([\"testds/Y.csv\"]).skip(1).map(lambda line: read_rowY(line))\n",
    "\n",
    "dataset = tf.contrib.data.Dataset.zip((dataX, dataY))\n",
    "dataset = dataset.repeat(-1)\n",
    "dataset = dataset.shuffle(buffer_size=10000)\n",
    "dataset = dataset.batch(4)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a session and have a look at what it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ : [[ 0.62039006  1.28688061  0.64067596 -1.37342143 -0.85903567]\n",
      " [ 0.68092704 -1.66005695 -0.04232123 -0.89476609  0.71628618]\n",
      " [-0.415335   -0.9808777   0.85739839  0.94326776  0.63954777]\n",
      " [ 0.80425245 -1.87975717  0.4975239  -1.07296443  0.80229783]]\n",
      "y_ : [[1]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "x_ : [[ 0.57320696 -0.11811064  0.78913075 -1.008322   -0.08786258]\n",
      " [-0.32951188 -0.83351856 -1.22482932  0.75938696  0.53726977]\n",
      " [ 0.61345357 -0.02652777  0.55074894 -1.09903502 -0.14796428]\n",
      " [ 0.63816696 -0.37510505 -0.13243483 -1.07401562  0.03372843]]\n",
      "y_ : [[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "x_ : [[-1.5106796   1.69215465  0.70041883  2.38206697 -0.5141077 ]\n",
      " [-0.58247679 -1.05631042 -0.56845391  1.25919414  0.72449857]\n",
      " [-0.997747   -1.4155184   1.31619883  2.07838154  1.02832949]\n",
      " [ 0.35767436  1.5591954   2.29348445 -0.95478755 -0.93658334]]\n",
      "y_ : [[1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "x_ : [[-0.96823376 -1.31148112 -1.29235435  2.00450706  0.96434194]\n",
      " [-0.415335   -0.9808777   0.85739839  0.94326776  0.63954777]\n",
      " [ 0.28717077 -0.40139347  0.47839844 -0.43691844  0.14078017]\n",
      " [-0.11041786  0.79478014 -0.60194492  0.04028892 -0.3999677 ]]\n",
      "y_ : [[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "x_ : [[ 0.65248853 -1.58604765 -0.78037888 -0.85832953  0.68384486]\n",
      " [-1.18799794 -1.43703687 -0.97685611  2.42515779  1.09028029]\n",
      " [-0.415335   -0.9808777   0.85739839  0.94326776  0.63954777]\n",
      " [ 0.57320696 -0.11811064  0.78913075 -1.008322   -0.08786258]]\n",
      "y_ : [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'coord' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-786e62628e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     print(\"y_ : {} | {}\".format(y_,dataset_created[1][(4*i):(4*(i+1))]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     print(\"label : {} | {}\".format(label, dataset_created[1][i] ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'coord' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(iterator.initializer)\n",
    "\n",
    "# Start populating the filename queue.\n",
    "# coord = tf.train.Coordinator()\n",
    "# threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "for i in range(5):\n",
    "    # Retrieve a single instance:\n",
    "    x_, y_ = sess.run(next_element)\n",
    "    print(\"x_ : {}\".format(x_,dataset_created[0][(4*i):(4*(i+1)),:]))\n",
    "    print(\"y_ : {}\".format(y_,dataset_created[1][(4*i):(4*(i+1))]))\n",
    "#     print(\"x_ : {} | {}\".format(x_,dataset_created[0][(4*i):(4*(i+1)),:]))\n",
    "#     print(\"y_ : {} | {}\".format(y_,dataset_created[1][(4*i):(4*(i+1))]))\n",
    "#     print(\"label : {} | {}\".format(label, dataset_created[1][i] ))\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}